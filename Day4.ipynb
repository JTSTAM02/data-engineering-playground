{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12249d76-e93a-45f2-9f91-a7e20cf17454",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Day4\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import col, row_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54917112-1441-4d14-971f-965daee8a688",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+-----+---------------+\n",
      "|student_id|   name|grade|attendance_code|\n",
      "+----------+-------+-----+---------------+\n",
      "|         1|  Alice|    5|              P|\n",
      "|         2|    Bob|    5|              A|\n",
      "|         3|Charlie|    6|              P|\n",
      "|         4|  David|    6|              P|\n",
      "|         5|    Eva|    5|              P|\n",
      "+----------+-------+-----+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [\n",
    "    (1, \"Alice\", 5, \"P\"),\n",
    "    (2, \"Bob\", 5, \"A\"),\n",
    "    (3, \"Charlie\", 6, \"P\"),\n",
    "    (4, \"David\", 6, \"P\"),\n",
    "    (5, \"Eva\", 5, \"P\"),\n",
    "]\n",
    "\n",
    "columns = [\"student_id\", \"name\", \"grade\", \"attendance_code\"]\n",
    "\n",
    "df = spark.createDataFrame(data, columns)\n",
    "\n",
    "df.show()\n",
    "\n",
    "window_spec = Window.partitionBy(\"grade\").orderBy(\"student_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d9becd4-ecd7-4ed9-88f6-539bb2898980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+-----+---------------+----------+\n",
      "|student_id|   name|grade|attendance_code|row_number|\n",
      "+----------+-------+-----+---------------+----------+\n",
      "|         1|  Alice|    5|              P|         1|\n",
      "|         2|    Bob|    5|              A|         2|\n",
      "|         5|    Eva|    5|              P|         3|\n",
      "|         3|Charlie|    6|              P|         1|\n",
      "|         4|  David|    6|              P|         2|\n",
      "+----------+-------+-----+---------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_with_rownum = df.withColumn(\n",
    "    \"row_number\",\n",
    "    row_number().over(window_spec)\n",
    ")\n",
    "\n",
    "df_with_rownum.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a59ab5c-41c9-4367-9ac5-74dd294d6a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+-----+---------------+----------+\n",
      "|student_id|   name|grade|attendance_code|row_number|\n",
      "+----------+-------+-----+---------------+----------+\n",
      "|         1|  Alice|    5|              P|         1|\n",
      "|         2|    Bob|    5|              A|         2|\n",
      "|         5|    Eva|    5|              P|         3|\n",
      "|         3|Charlie|    6|              P|         1|\n",
      "|         4|  David|    6|              P|         2|\n",
      "+----------+-------+-----+---------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_with_rownum = df.withColumn(\n",
    "    \"row_number\",\n",
    "    row_number().over(window_spec)\n",
    ")\n",
    "\n",
    "df_with_rownum.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b9e6b57-1b3f-46e6-a8ef-586192638313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- Window [row_number() windowspecdefinition(grade#2L, student_id#0L ASC NULLS FIRST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS row_number#35], [grade#2L], [student_id#0L ASC NULLS FIRST]\n",
      "   +- Sort [grade#2L ASC NULLS FIRST, student_id#0L ASC NULLS FIRST], false, 0\n",
      "      +- Exchange hashpartitioning(grade#2L, 200), ENSURE_REQUIREMENTS, [plan_id=132]\n",
      "         +- Scan ExistingRDD[student_id#0L,name#1,grade#2L,attendance_code#3]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_with_rownum.explain()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6f190765-9fa8-4638-8878-c1d5b6e174e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+-----+---------------+---+\n",
      "|student_id|   name|grade|attendance_code| rn|\n",
      "+----------+-------+-----+---------------+---+\n",
      "|         1|  Alice|    5|              P|  1|\n",
      "|         2|    Bob|    5|              A|  2|\n",
      "|         5|    Eva|    5|              P|  3|\n",
      "|         3|Charlie|    6|              P|  1|\n",
      "|         4|  David|    6|              P|  2|\n",
      "+----------+-------+-----+---------------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import row_number, col\n",
    "\n",
    "window_spec = Window.partitionBy(\"grade\") \\\n",
    "                    .orderBy(col(\"student_id\"))\n",
    "\n",
    "df_ranked = df.withColumn(\n",
    "    \"rn\",\n",
    "    row_number().over(window_spec)\n",
    ")\n",
    "\n",
    "df_ranked.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c2eed681-0bc8-4195-bf53-59af12e468fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import sum\n",
    "\n",
    "window_spec = Window.partitionBy(\"grade\")\n",
    "\n",
    "df_with_sum = df_ranked.withColumn(\n",
    "    \"total_rns\",\n",
    "    sum(\"rn\").over(window_spec)\n",
    ")\n",
    "\n",
    "df_with_sum.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0a0197-556e-4c3f-94fc-b534a0986a64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
